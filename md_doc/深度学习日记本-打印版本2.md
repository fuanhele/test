# 深度学习00

[toc]



[Typora正确食用方法](https://www.cnblogs.com/luckforefforts/p/13642696.html)



# 工具：

借助一些工具可以帮助我们做记录。

## TensorBoard

[很全的文章](https://www.cnblogs.com/zhangxiann/p/13617142.html)  [简洁的文章](https://www.jianshu.com/p/46eb3004beca)  

可以记录训练过程中的auc，acc，lr，f1的变化过程。

可以使用直方图，记录图像，卷积核可视化，每一层图像处理可视化。

## torchsummary summary

tensorboard是基于TensorFlow的可视化训练，pytorch没有很好的 模型可视化工具，TorchSummary对此提供了补足，极大降低了模型可视化难度，也方便模型参数等数据的统计。

TorchSummary提供了更详细的信息分析，**包括模块信息（每一层的类型、输出shape和参数量）、模型整体的参数量、模型大小、一次前向或者反向传播需要的内存大小等。** 

TorchSummary的使用只要提供给summary函数模型以及输入的size就可以了。

```python
from torchsummary import summary
summary(model, input_size=(channels, H, W))

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.re
        lu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Net().to(device)

summary(model, (1, 28, 28))
# 还可以加入device参数，指定模型是在cpu还是cuda
# summary(model,(1,28,28),device='cpu')

# 输出大概类似下面
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 24, 24]             260
            Conv2d-2             [-1, 20, 8, 8]           5,020
         Dropout2d-3             [-1, 20, 8, 8]               0
            Linear-4                   [-1, 50]          16,050
            Linear-5                   [-1, 10]             510
================================================================
Total params: 21,840
Trainable params: 21,840
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 0.08
Estimated Total Size (MB): 0.15
----------------------------------------------------------------
```

对于多输入的情况，只要传入的`input_size`改为一个安装输入所需size组成的列表就行，示例如下。

```python
class SimpleConv(nn.Module):
    def __init__(self):
        super(SimpleConv, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
        )

    def forward(self, x, y):
        x1 = self.features(x)
        x2 = self.features(y)
        return x1, x2


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleConv().to(device)

summary(model, input_size=[(1, 16, 16), (1, 28, 28)])

# 输出结果
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 1, 16, 16]              10
              ReLU-2            [-1, 1, 16, 16]               0
            Conv2d-3            [-1, 1, 28, 28]              10
              ReLU-4            [-1, 1, 28, 28]               0
================================================================
Total params: 20
Trainable params: 20
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.77
Forward/backward pass size (MB): 0.02
Params size (MB): 0.00
Estimated Total Size (MB): 0.78
----------------------------------------------------------------
```



## thop profile计算参数量

[将flops和paras讲述很好的文章，说明了两者的区别](https://blog.csdn.net/qq_40507857/article/details/118764782)

```python
from thop import profile

flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32),) if args.dataset == 'cifar10'
                            else (torch.randn(1, 3, 224, 224),), verbose=False)
```

flops 是浮点运算数，理解为计算量，用来衡量模型的复杂度。

params 是模型中的参数。



## 	获取argparse定义的参数

```python
import argparse
parse = argparse.ArgumentParser(description='The Firse Line')
parse.add_argument('data', metavar='DIR', help='path to dataset')

args = parse.parse_args()
print(args.data)
```

参数解读：

- [ ] action：命令行遇到参数时的动作，默认值是store
  当action=sotre_true时，有值传入就为True，无值传入就是False
- [ ] default：不指定参数时的默认值
- [ ] type：命令行参数应该被转换成的类型
- [ ] metavar：在usage说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称。用来控制部分命令行参数的显示，只是影响参数的显示信息，不影响代码内部获取命令行参数的对象。
- [ ] dest：解析后的参数名称

## random.seed()

seed()方法改变随机数生成器的种子，可以在调用其他随机模块函数之前调用此函数。

参数可有可无，当没参数的时候，每次生成的随机种子不一样。
当有参数且参数相等的时候，生成的随机种子相同。
有参但不相等，生成的种子不同。

## cuda的随机种子

`torch.backends.cudnn.deterministic = True`

这个是设置cuda的随机种子，为了确保每次的训练结果相同，需要将这个flag设置为True，每次的卷积算法是确定的，即默认算法，配合上torch的随机种子，应该可以保证每次运行网络的时候相同输入的输出是固定的。





***

---

# torchvision

## torchvision.transforms

[torchvision.transforms的图像预处理](https://blog.csdn.net/m0_37163827/article/details/111284328)

- [ ] <kbd>Compose()</kbd> 参数是对transform所有图像进行操作，会将transforms列表遍历一次。

  ```python
  transforms.Compose([
       transforms.CenterCrop(10),
       transforms.ToTensor(),
   ])
  ```

- [ ] <kbd>Lambda</kbd> 对图片进行处理，有时候我们不想检测图片的全部，只想检测部分，就通过一个匿名函数对图片进行处理。
- [ ] <kbd>Normalize(mean,std)</kbd> 对图片用均值和标准差归一化一张向量图像
  第一个参数mean：均值
  第二个参数std：标准差
- [ ] <kbd>ToTensor()</kbd> 将PIL图片或者numpy.ndarray转成tensor，注意形状顺序和通道顺序是有区别的，ToTensor是做归一化且改变了形状顺序。
- [ ] <kbd>RandomResizedCrop()</kbd> 缩放后随机裁剪，参数size指定了裁剪的大小。
- [ ] <kbd>RandomHorizontalFlip()</kbd> 以概率p水平翻转给定的图像。默认0.5

## torchvision.datasets

- [ ] <kbd>ImageFolder()</kbd> 是一个通用的数据加载器，对数据集的训练，验证或者测试。
  参数1：root 图片存储的根目录
  参数2：transform 对图片进行预处理的操作，这里可以用transforms.Compose()对每一张图片做一组连续的操作
  参数3：target_transform 对图片类别进行预处理的操作

https://blog.csdn.net/qq_36178899/article/details/84986563)



# 常用命令

1. 查看cuda版本：`nvidia-smi` 
2. windows中和grep对应的命令： `findstr`      `pip list| findstr "torch"` 
3. `pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/torch1.10.0/index.html`
4. 统计目录中文件数目：`ls /data2/lily/ala/ | wc -l` 
5. scp复制文件 `scp -r /data2/lily/ala lily@172.31.224.43:/pubdata/lily/` 
6. 复制目录中的前n个文件 `ls /data2/lily/output/srnet_datagen/i_s/ |head -n 10 |xargs -i cp '/data2/lily/output/srnet_datagen/i_s/'{} /home/lily/SRNet-datagen/i_s` 
   xargs是给其他命令传递参数的过滤器，也是组合多个命令的一个工具。
   当 -i 与 xargs 结合使用，每一个参数命令都会被执行一次.
7. python和python3 
   `echo alias python=python3 >> ~/.bashrc` 
   `source ~/.bashrc`
8. pycharm 快速折叠全部代码，展开全部代码
   `Ctrl+Shift+-`      `Ctrl+Shift++`
9. 查看文件行数: `wc -l 文件路径`
10. 查看gpu上运行的进程号，根据进程号来终止进程`fuser -v /dev/nvidia*`  `kill -9 进程号`






# python基础

### sort和sorted

**sort 与 sorted 区别：**

sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作。

list 的 sort 方法返回的是对已经存在的列表进行操作，无返回值，而内建函数 sorted 方法返回的是一个新的 list，而不是在原来的基础上进行的操作。

### hasattr

**hasattr(Object, name)** 函数用于判断对象是否包含对应的属性。

### eval

用来执行字符串表达式，并返回值

```python
>>>x = 7
>>> eval( '3 * x' )
21
```

### 参数中的* 和 **

`*args`表示将参数作为一个元组使用

`**args`表示将参数作为一个字典使用

一言概之，* 主要使用在函数参数中，在定义函数中添加是为了在调用该函数时直接将多个参数转换成一个元组，而在调用函数时参数添加 *，是为了将列表/元组转化成多个参数。

** 也主要使用在函数参数中，在定义函数中添加是为了在调用该函数时可以添加任意个键值对转出一个字典，而在调用函数时在列表中添加 **，是为了将字典转化成多个参数。

```python
def func1(*a):
	print(a)
	
def func2(**b):
	print(b)
func1(1,2,3,4,5)			#这样可以将多个参数变成一个元组
func2(name='mr',age='22')	#这样可以将多个键值对变成一个字典
	
def f1(a,b,c):
	print(a)
def f2(name,age,sex):
	print(name)
l = [1,2,3]
d = {"name":'mr',"age":22,"sex":'boy'}
f1(*l)						#将列表、元组变成多个参数
f2(**d)						#将字典转成赋值参数，name='mr',age=22,sex='boy'
 
func1(*l)					#先将参数转成多个参数，在函数参数中又转成元组		
func2(**d)					#先将参数转成多个键值对，在函数参数中又转成字典

》》》输出结果
(1, 2, 3, 4, 5)
{'age': '22', 'name': 'mr'}
1
mr
(1, 2, 3)
{'age': 22, 'sex': 'boy', 'name': 'mr'}
```

### with torch.no_grad():

被`with torch.no_grad()` 包裹的代码不会进行梯度计算。

### polling的介绍

[知乎文章](https://www.zhihu.com/question/303215483/answer/615115629) 

### python操作excel

[知乎文章](https://zhuanlan.zhihu.com/p/259583430)

### python操作文件等

[博客园](https://www.cnblogs.com/sui776265233/p/10843641.html) 

### re的使用

python中 正则化 re模块

1. 从字符串中删除标点符号：`re.sub(r'[^\w\s]','',str1)`

2. 只保留字符串中的中文：

   ```python
   pattern = re.compile(r'[^\u4e00-\u9fa5]')
   chinese = re.sub(pattern, '', str1)
   ```

3. 只保留字符串中的非中文：

   ```python
   pattern = re.compile(r'[\u4e00-\u9fa5]')
   unchinese = re.sub(pattern, "", str1)
   ```


### glob.glob(string)

返回符合规则的所有文件路径。用它可以查找符合特定规则的文件路径名。跟使用windows下的文件搜索差不多。查找文件只用到三个匹配符：” * ”, “?”, “[]”。” * ”匹配0个或多个字符；”?”匹配单个字符；”[]”匹配指定范围内的字符，如：[0-9]匹配数字。

## 

# Numpy基础知识

numpy是python中科学计算的核心库，提供了一个高表现、高位矩阵计算工具。

### Array Broadcasting in Numpy

广播机制就是：如果两个都是矩阵，要求矩阵形状一样，然后对应位置相乘；

如果一个是矩阵另一个是数字，就是把数字和矩阵中的每个元素相乘。

### 数组：

```python
a = np.array([1, 2, 3]) #创建一个一维数组
print(type(a)) #<class	'numpy.ndarray'>
print(a.dtype) #int64
print(a.shape) #(3,)

# 创建指定大小的随机数组
np.random.rand(3,4,5)  # 三维
```

可以通过下标来访问或者修改数组中的元素。

```python
b = a[:2, 1:3] #数组a的前两行 其中的1,2列
```

### 基本函数

sum

```python
x = np.array([[1, 2], [3, 4]])
print(np.sum(x)) #10
print(np.sum(x, axis=0)) #[4 6] 按列求和
print(np.sum(x, axis=1)) #[3 7] 按行求和
```

### np.random.choice

从一个**一维对象**中随机抽取样本，可以指定抽取后组成的大小，以及抽取每个样本的概率。  

[参考文章]: https://blog.csdn.net/ImwaterP/article/details/96282230

```python
numpy.random.choice(a, size=None, replace=True, p=None)
#从a(只要是ndarray都可以，但必须是一维的)中随机抽取数字，并组成指定大小(size)的数组
#replace:True表示可以取相同数字，False表示不可以取相同数字
#数组p：与数组a相对应，表示取数组a中每个元素的概率，默认为选取每个元素的概率相同。
```



### np.save()  &  np.load()

`np.save(filename, nparray)`:保存数组到filename中，一般以npy结尾

`np.load(filename)`:从npy文件中提取数组。

### array.flatten()

将numpy数组压缩成一维数组，[[1,2],[3,4],[5,6]]  使用flatten之后变为  [1,2,3,4,5,6]

### np.newaxis

给numpy数组增加一个维度，例：

```python
>> x = np.arange(3)
>> x
array([0, 1, 2])
>> x.shape
(3,)

>> x[:, np.newaxis]
array([[0],
       [1],
       [2]])

>> x[:, None]
array([[0],
       [1],
       [2]])

>> x[:, np.newaxis].shape
 (3, 1)
```

### np.vstack() np.hstack()

np.vstack((arr1, arr2)) 沿着竖直方向将矩阵堆叠起来。

np.hstack((arr1, arr2)) 沿着水平方向将矩阵堆叠起来。

![image-20211210185525991](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211210185525991.png)

![image-20211210190657748](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211210190657748.png)

### np.where

```
tamper_mask = np.array([[0,0,1],[1,1,0]])
tamper_index = np.where(tamper_mask > 0)

# tamper_index >>  tuple:2
# tuple(0) >> ndarray:(3,) >> [0 1 1]
# tuple(1) >> ndarray:(3,) >> [2 0 1]

tamper_mask中大于0的位置有：(0,2)(1,0)(1,1)
所以tamper_index中两个数组对应位置就是满足条件的数字索引。

```

### np.clip

将数组中的值修改为在某个区间范围内，不在区间范围内的 按最小值或者最大值修改。

```
import numpy as np
x=np.array([1,2,3,5,6,7,8,9])
np.clip(x,3,8)

>>> array([3, 3, 3, 5, 6, 7, 8, 8])
```

### expand_dims

numpy的增加维度, 对应pytorch的unsqueeze

`np.expand_dims(arr, 0)` 在第0维增加一个维度

### swapaxes交换维度

`x.swapaxes(0, 2) ` 

### np.r\_() np.c_()

np.r_是按列连接两个矩阵，就是把两矩阵上下相加，要求列数相等。

np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等。

### np.atleast_1d

将输入的多个数组，转换为每个至少一维的数组并返回

```python
>>> np.atleast_1d(1, [3, 4])
[array([1]), array([3, 4])]
```

### np.prod

连乘操作，将numpy数组中的所有元素相乘，得到结果。

可以指定维数，如果对一个2*3的数组进行操作，指定axis=0，数组变为1\*3

指定axis=1,数组变成2\*1   .   总结为对哪个维度进行操作，哪个维度就会压缩。

```
>>> np.prod([[1.,2.],[3.,4.]])
24.0
>>> np.prod([[1.,2.],[3.,4.]], axis=1)
array([  2.,  12.])
```

### np.linalg

np.linalg是numpy的线性代数操作的内容

[简单描述文章](https://blog.csdn.net/jiang425776024/article/details/86822875) 

norm实现数据归一化

其他方法还可以求系数，逆矩阵，广义逆矩阵，行列式，线性方程组等。

### np.mod

计算两个数组对应位置元素的余数





# Pytorch基础知识

pytorch是一个拥有强力GPU加速的张量和动态构建网络的库，主要构件是张量，所有可以把PyTorch当做Numpy来用，好多操作都是类似的，但是要比Numpy快很多倍。

### tensor运算

```
# matmul 矩阵乘法
# mul 对应元素相乘
```



### torch.Tensor

```
torch.Tensor(4,3) # 生成4行3列的随机数，注意这个随机数非常随机，可能很大或很小
torch.Tensor([4,3])  # [4., 3.] 0行2列
```



### numpy--tensor互相转换

```python
import torch
import numpy as np
# 创建一个 numpy ndarray
numpy_tensor = np.random.randn(10, 20)
#可以通过两种方式将numpy的ndarray转换为tensor上
pytorch_tensor1 = torch.Tensor(numpy_tensor)
pytorch_tensor2 = torch.from_numpy(numpy_tensor)
# 同时也可以使用方法将tensor转化为ndarray
# 1.如果tensor在CPU上，可以直接转换
numpy_array = pytorch_tensor1.numpy()
# 2.如果tensor在GPU上，需要经过CPU才能转换
numpy_array = pytorch_tensor2.cpu().numpy()
```

### tensor使用GPU加速

```python
# 第一种方式：定义cuda数据类型
dtype = torch.cuda.FloatTensor #定义默认GPU的数据类型
gpu_tensor = torch.randn(10, 20).type(dtype)
# 第二种方式：推荐使用
gpu_tensor = torch.randn(10, 20).cuda(0) #放到第一个GPU上
```

```python
# 有两种方式访问到tensor的大小
print(pytorch_tensor.shpae) #torch.Size([10, 20])
print(pytorch_tensor.size())
# 得到tensor的数据类型
print(pytorch_tensor.type()) #torch.FloatTensor
# 得到tensor的维度
print(pytorch_tensor.dim()) # 2
# 得到tensor的所有元素的个数
print(pytorch_tensor.numel()) #200
```

### tensor的操作

```python
x = torch.ones(2, 2) #得到一个大小是2*2的全1tensor
print(x.type()) #torch.FloatTensor
# 将浮点型转换为整型
x = x.long()
x = x.float()

# 创建一个tensor
x = torch.randn(4, 3)
# 取每行的最大值
max_value, max_index = torch.max(x, dim=1)
# 取每列的最大值
max_value, max_index = torch.max(x, dim=0)
# 对每一行求和
sum_x = torch.sum(x, dim=1)
```

```python
# 对tensor增加或者减少维度
x = x.unsqueeze(0) #在第一维增加 [4,3]-->[1,4,3]
x = x.unsqueeze(1) #在第二维增加 [1,4,3]-->[1,1,4,3]
x = x.squeeze(0) #第一维减少 [1,1,4,3]-->[1,4,3]
x = x.squeeze() #不指定参数 删去第一维

# 使用permute和transpose进行维度交换
x = torch.randn(3,4,5)
x = x.permute(1,0,2) #[3,4,5]-->[4,3,5]
x = x.transpose(0,2) #[4,3,5]-->[5,3,4]
```

```python
# 使用view对tensor进行reshape
x = x.view(-1,5) #-1表示任意大小，5表示第二维变成5
# [3,4,5]-->[12,5]
x = x.view(3,20) #[12,5]-->[3,20]
```

detach: 中断梯度计算。它可以使两个计算图的梯度传递断开，从而实现我们所需的功能。

torch.mul(a,b): 矩阵点乘，维数不限，broadcast，当a，b维度不一致时，会自动填充到相同维度点乘。

### torch.repeat

对tensor某个维度进行复制  [参考文章](https://blog.csdn.net/qq_40491305/article/details/115110105)

```python
temp = torch.ones((32, 1, 3, 3), dtype=torch.float)
target = temp.repeat(1, 3, 1, 1)
print(temp.shape)
print(target.shape)
```

### tensor的inplace操作

即操作的对象是自己，可以不用复制给其他变量,不需要另外开辟内存空间，方法很简单，一般是在操作的符号后面加上`_`,

```python
x = torch.ones(3,3)
y = torch.randn(3,3)
x.unsqueeze_(0)
x.transpose_(1,0)
x.add_(y) #将x和y相加的结果直接赋值给x
print(x)
```

### torch.ge(input, output, out)

比较两个相同形状的tensor，逐个对比，如果input>=output 那么输出的out对应位置就是1 ，否则就是0

```python
torch.ge(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]]))
 1  1
 0  1
[torch.ByteTensor of size 2x2]
```

在神经网络中计算准确率的时候也可以用到，比如想找到计算结果中概率大于50%的那个预测值，就能用到ge函数。

```python
# y_pred是一个tensor，里面存储的是对某一个数据的预测值
mask = y_pred.ge(0.5) #将预测值大于0.5的都置1
acc = (mask == y_data).sum().data[0] / y_data.shape[0] #计算准确率
```

### torch.tensor.fill_(value)

让tensor中的值全部变为value.

### torch.utils.data.DataLoader()

除了dataset是必选的，其余都是可选的参数。

1. dataset：需要训练的数据集
2. batch_size：每批要加载多少个数据样本
3. shuffle：为True每次epoch都重新打乱样本
4. sampler：定义了怎么从数据集中取样本，如果指定了方法，那么shuffle一定不能为True。
5. num_workers：加载数据需要多少个子进程。
6. pin_memory：True固定内存大小。

### torch.nn.DataParallel

用多个GPU来加速训练，一般会加入这个语句：

`device_ids = [0, 1, 2]` 

`net = torch.nn.DataParallel(net, device_ids=devic_ids, output_device=None)`

但是第一块卡的显存会占的更多一点，因为output_device一般不写，而默认是将输出放到第一块卡上device[0]上，所以第一块显卡的负载就稍微大些。也就是说虽然计算是分开计算的，但是最后需要汇总到一起，就会出现这种情况。

还会出现的一种情况 默认汇总的卡都是0号卡，如果这时0号卡被别人占用了，那么如果直接指定：`os.environ["CUDA_VISIBLE_DEVICES"] = "2, 3"` 就会出现错误，我们需要在前面加上`os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"` 才能让结果汇总在我们指定的卡上。

### nn.Parameter

含义是将一个固定不可训练的tensor==转换成可以训练的类型parameter==，并将这个parameter绑定到这个module里面(net.parameter()中就有这个绑定的parameter，所以在参数优化的时候可以进行优化的)，所以经过类型转换这个self.v变成了模型的一部分，成为了模型中根据训练可以改动的参数了。使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。

### nn.Linear

用于设置网络中的全连接层

```
self.encoder_fc1 = nn.Linear(3, 32) # 输入向量的最后一个维度一定得是3,
# 比如输入这个全连接层(28, 28, 3),输出(28, 28, 32)
```

### F.mse_loss() 

或者 torch.nn.MSELoss()

参考文章：https://blog.csdn.net/nyist_yangguang/article/details/119217125

### torch.nn

输入nn.Conv2d和输出的图片形状都是：==NCHW（你瞅好哇）==

1. `nn.Conv2d(input_channel,output_channel,kernel_size,stride,padding,dilation,bias,groups)`

   1. input_channel: 输入的通道数，灰图是1，彩图是3，同时也表示了卷积核的通道数。
   2. output_channel: 输出的通道数，也就是输出的卷积核的个数。
   3. kernel_size: 卷积核的大小 3就表示3*3
   4. stride: 卷积核每次移动的步长。
   5. padding: 在原图像周围填充多少圈0像素。
   6. groups:将输入通道进行分组计算。
      举例：比如说输入6通道，输出9通道，按理说需要9个6通道的卷积核。但是现在设置groups=3，就等于说将输入的6通道分成3组，两个一组。由于输出通道数一定等于卷积核的个数，所以需要9个卷积核，将这9个卷积核也分成3组，每组有3个卷积核负责。输入和输出的组分别对应，那么对于每一个组而言：输入通道为2，输出通道为3，即每组需要3个通道数为2的卷积核。总共三组，就需要9个通道数为2的卷积核。
      设置groups就相当于减少了计算量，至于与普通卷积有什么区别后来再进行补充。
   7. dilation: 默认是1，为1时感受野增大，如图：
   8. <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211012094955716.png" alt="image-20211012094955716" style="zoom: 33%;" />
   9. bias: 每个卷积核的偏置系数
   10. 整体工作流程：[参考文章](https://blog.csdn.net/qq_41542989/article/details/118466971) <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211012095146190.png" alt="image-20211012095146190" style="zoom:50%;" />
         <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211012095215067.png" alt="image-20211012095215067" style="zoom: 33%;" />

2. `nn.Conv2d(...).weight(Tensor)`: 

   Conv2d(...)调用后会自动初始化weight和bias，使用这个方法可以自定义weight和bias。

   ![image-20211020143919481](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211020143919481.png)

   

3. `nn.GroupNorm(num_groups, num_channels)`
   将channels切分为许多组进行归一化。

   1. num_groups：组数
   2. num_channels: 通道数量

4. 1*1卷积核的作用

   如果卷积的输出输入都只是一个平面，那么1x1卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。 但卷积的输出输入是长方体，所以1x1卷积实际上是对每个像素点，在不同的channels上进行线性组合（信息整合），且保留了图片的原有平面结构，调控depth，从而完成升维或降维的功能。
   
5. 

### torch.manual_seed(int seed)

在需要生成随机数的实验中，确保每次运行.py文件时，生成的随机数都是固定的，这样每次实验结果显示也就一致了。

```python
torch.manual_seed(1)
torch.rand(1,2)
# 无论执行多少次，输出的结果是一样的。
# 如果不用第一行，那每次结果就不同的。
```

### torch.cuda.device_count()

返回当前主机可用GPU的数量。

### torch.multiprocessing.spawn()

如果其中一个进程以非零退出状态退出，则会杀死其余进程，并引发异常，导致终止。

```
torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))
#main_worker 函数
# nproce 派生的进程数量
# args 传递给函数的参数
```

- **进程组的[相关概念](https://link.zhihu.com/?target=https%3A//github.com/pytorch/examples/blob/master/distributed/ddp/README.md)**

- - **GROUP**：进程组，大部分情况下DDP的各个进程是在同一个进程组下
  - **WORLD_SIZE**：总的进程数量 (原则上一个process占用一个GPU是较优的)
  - **RANK**：当前进程的序号，用于进程间通讯，rank = 0 的主机为 master 节点
  - **LOCAL_RANK**：当前进程对应的GPU号

### torch.distributed.init_process_group

初始化进程组

### torch.cat

`torch.cat(A, B, 1)` 最后一个参数是0或者1，0的话将AB两个张量 竖着拼 需要列数相同；1的话将AB两个张量 横着拼 需要行数相同。

### torch.squeeze(input, dim)

如果只传入一个Tensor，那么就是去掉Tensor中所有维度为1的。

如果又传入了dim，并且Tensor中的第dim维度是1，就去掉这个维度，如果这个地方的维度不是1，就什么也不做。

### lr_scheduler.ReduceLROnPlateau

当网络的评价指标不再提升的时候，可以通过降低网络的学习率来提高网络性能。

```python
class torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10,verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)
```

- [ ] optimer指的是网络的优化器 梯度下降函数
- [ ] mode (str) ，可选择‘min’或者‘max’，min表示当监控量停止下降的时候，学习率将减小，max表示当监控量停止上升的时候，学习率将减小。默认值为‘min’
- [ ] ==factor== 学习率每次降低多少，==new_lr = old_lr * factor==
- [ ] ==patience=10==，容忍网路的性能不提升的次数，高于这个次数就降低学习率
- [ ] verbose（bool） - 如果为True，则为每次更新向stdout输出一条消息。 默认值：False
- [ ] threshold（float） - 测量新最佳值的阈值，仅关注重大变化。 默认值：1e-4
- [ ] cooldown： 减少lr后恢复正常操作之前要等待的时期数。 默认值：0。
- [ ] min_lr,学习率的下限
- [ ] eps ，适用于lr的最小衰减。 如果新旧lr之间的差异小于eps，则忽略更新。 默认值：1e-8。

```
scheduler.step(val_loss)
```

当val_loss满足设置的条件时，就降低学习率。

### torch.clamp

`torch.clamp(input, min=None, max=None, *, out=None) → Tensor`

input:Tensor 

返回值也是Tensor

作用是将input的tensor限制在范围[min, max]这个区间内。

### torch.nn.functional.pad(input, pad,mode,value)

input：四维或者五维的tensor Variabe
pad：不同Tensor的填充方式
		1.四维Tensor：传入四元素tuple(pad_l, pad_r, pad_t, pad_b)，
		指的是（左填充，右填充，上填充，下填充），其数值代表填充次数
		2.六维Tensor：传入六元素tuple(pleft, pright, ptop, pbottom, pfront, pback)，
		指的是（左填充，右填充，上填充，下填充，前填充，后填充），其数值代表填充次数
mode： ’constant‘, ‘reflect’ or ‘replicate’三种模式，指的是常量，反射，复制三种模式
value：填充的数值，在"contant"模式下默认填充0，mode="reflect" or "replicate"时没有value参数







# cv2

### cv2.imread

```
# 读取灰度图 有两种方法
cv2.imread(image, cv2.IMREAD_GRAYSCALE)
cv2.imread(image, 0)

# 读取彩色图像
cv2.imread(image, 1)

```

### cv2.imshow

不推荐用这种方法，会让图像显得很大

`cv2.imshow('img', image)` 使用时需要结合下面这一句，否则图像会一闪而过

`cv.waitKey(0)  # 等待键盘输入 `

推荐使用画图方法：

```python
import matplotlib.pyplot as plt

fig, ax = plt.subplots(1, 2)  # row = 1, col = 2 创建一个一行两列的画布

ax[0].imshow(image)
ax[1].imshow(image_grey, cmap='gray')  # 将画布设置为灰度图模式

# ax[0].axis("off"), ax[1].axis("off")  # 这个打开后，图像上会不显示坐标

# plt.savefig("result.jpg", dpi = 300, bbox_inches = "tight")
plt.show()

```



### cv2.flip(img, mode)

翻转图片 ，mode=0垂直翻转；mode=1水平翻转；mode=-1水平垂直翻转。

### cv2.pyrDown(image)  &  pyrUp()

cv2.pyrDown()函数首先对原始图像进行高斯变换，再通过==抛弃偶数行和偶数列==实现下采样。

cv2.pyrUp() 函数首先在原始图像的每个像素的==右侧和下侧分别插入零值列和零值行==，得到一个偶数行，偶数列（新增的行和列）都是零值的新图，在进行高斯变换，得到上采样的结果图像。

### cv2.resize

```
resize(image, size, fx, fy, interpolation)
# image 原图，size输出图大小，fx fy图片缩放比例，interpolation插值方式
```

假设源图像大小为mxn，目标图像为axb。那么两幅图像的边长比分别为：m/a和n/b。注意，通常这个比例不是整数，编程存储的时候要用浮点型。目标图像的第（i,j）个像素点（i行j列）可以通过边长比对应回源图像。其对应坐标为（i* m/a,j* n/b）。
最近邻插值是对这个坐标进行四舍五入取整；
而双线性插值是从这个坐标相近的四个真实存在的点中找到最接近的点。

[参考文章，看后半部分]: https://blog.csdn.net/qq_37577735/article/details/80041586

1. 最近邻插值

   `cv.resize(img,(width,height),interpolation=cv.INTER_NEAREST)`

   会损失空间对称性

2. 双线性插值（默认方式）

   `cv.resize(img,(width,height),interpolation=cv.INTER_LINEAR)`


   显然，这个对应坐标一般来说不是整数，而非整数的坐标是无法在图像这种离散数据上使用的。双线性插值通过寻找距离这个对应坐标最近的四个像素点，来计算该点的值（灰度值或者RGB值）。如果你的对应坐标是（2.5,4.5），那么最近的四个像素是（2，4）、（2，5）、（3，4），（3，5）。
   若图像为灰度图像，那么（i，j）点的灰度值可以通过一下公式计算：
   f(i,j)=w1*p1+w2*p2+w3*p3+w4*p4;
   其中，pi(i=1,2,3,4)为最近的四个像素点，wi(i=1,2,3,4)为各点相应权值。关于权值的计算，在维基百科和百度百科上写的很明白。

### cv2.findContours

用来查找检测物体的轮廓，函数直接修改原图。

[参考文章]: https://blog.csdn.net/gaoranfighting/article/details/34877549

后面用cnt代表某一个轮廓

```
contours, hierarchy = cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
```

> para:
>
> > binary:需要检测的二值图像（记住：不是灰度图）
> >
> > cv2.RETR_TREE：轮廓的搜索模式
> >
> > cv2.CHAIN_APPROX_SIMPLE：轮廓的近似办法
>
> Returns：
>
> > contours（list）：轮廓本身, 图片中检测的多少轮廓，这个list中就包含多少。每个轮廓是一个ndarray，每个ndarray是轮廓上的点的集合。轮廓中并不是存储轮廓上所有的点，而是只存储可以用直线描述轮廓的点的个数，比如一个“正立”的矩形，只需4个顶点就能描述轮廓了。
> >
> > hierarchy：可选的hiararchy结果，这是一个ndarray，其中的元素个数和轮廓个数相同。差不多就是轮廓之间的等级关系，具体含义没有理解。

### cv2.contourArea

参数是轮廓点的集合（cnt），通过格林公式计算面积。

### cv2.boundingRect

根据轮廓点集合画出水平正矩形。

参数是轮廓点集合，返回值有四个：x y w h  (x,y)是矩形左上角的坐标,w h是矩形的宽高。

### cv2.minAreaRect(cnt)

获得这个轮廓的最小外接矩形，这个矩形可以是倾斜的。
返回值是tuple形式: ((x,y), (side1,side2), rotate_angle)
(x,y):矩形中心点坐标
(side1,side2):矩形两条边长
rotate_angle:矩形旋转角度
关于旋转角度的解释，具体可以看自己写的csdn文章:https://blog.csdn.net/LLY_pro/article/details/125830099?spm=1001.2014.3001.5501

### cv2.absdiff

获取差分图 就是将两幅图像作差。取绝对值

The function calculates **absolute** difference between two arrays.
dst(i)c = |src1(I)c − src2(I)c |
All the arrays must have the same data type and the same size (or ROI size).

### cv2.minAreaRect
找到轮廓的最小外接矩形，详见自己写的博客文章: https://blog.csdn.net/LLY_pro/article/details/125830099?spm=1001.2014.3001.5501





# shutil

### shutil.rmtree

`shutil.rmtree(path)`递归删除文件

### copyfile copy

`copyfile(src, dst)` src, dst 都需是文件名, 如果dst 存在或无权限，会抛出异常

`copy(src, dst)` dst 可以是目录名







# PIL

`from PIL import Image`

使用`Image.open('XXX.png')`读取到的图片，通道是在最后，HWC

使用`toTensor`方法可以将图片转换为tensor类型，并且维度发生变化，CHW





# os

### os.path()

[菜鸟教程](https://www.runoob.com/python3/python3-os-path.html)

主要用来获取文件的属性

os.path.join(path1,path2) 把目录和文件名合成一个路径。

### os.path.dirname(\__file__)

获取当前运行脚本的绝对路径

### os.path.exists(path)

是否存在这个路径或者这个文件

### 

### os.walk()

用于返回所在目录的文件名等信息。

```python
os.walk(top[, topdown=True[, onerror=None[, followlinks=False]]])
```

- **top** -- 是你所要遍历的目录的地址, 返回的是一个三元组(root,dirs,files)。
  - root 所指的是当前正在遍历的这个文件夹的本身的地址
  - dirs 是一个 list ，内容是该文件夹中所有的目录的名字(不包括子目录)
  - files 同样是 list , 内容是该文件夹中所有的文件(不包括子目录)
- **topdown** --可选，为 True，则优先遍历 top 目录，否则优先遍历 top 的子目录(默认为开启)。如果 topdown 参数为 True，walk 会遍历top文件夹，与top 文件夹中每一个子目录。
  自己实验结果：无论topdown为True还是False，都会遍历根目录和子目录，区别只不过是优先级的问题。True 优先遍历根目录，False优先遍历子目录。

### os.environ["WORLD_SIZE"]

[知乎](https://zhuanlan.zhihu.com/p/360405558)

`os.environ.keys()`用来获取当前系统下的映像对象。

`num_gpus = int(os.environ["WORLD_SIZE"])` 用来获取当前主机的进程数量，为后面多GPU同时处理数据做准备。

"WORLD_SIZE"是由torch.distributed.launch.py产生



# 其他内容

## model

### model.train()

model.train   model.eval主要用在Batch Normalization和Dropout层

如果模型中有BN层和Dropout，需要在训练时添加model.train,可以保证BN层能够用到每一批数据的均值和方差，对于Dropout，train是随机取一部分网络连接来训练更新参数。

### model.eval()

如果模型中有BN层和Dropout，在测试时添加eval，保证能够用全部训练数据的均值和方差，测试过程中要保证均值和方差不变。对于Dropout，eval利用了所有网络连接，不进行随机舍弃神经元。

训练完train样本后，生成的模型model要用来测试样本。在model(test)之前，需要加上`model.eval()`，否则的话，有输入数据，即使不训练，它也会改变权值。这是model中含有BN层和Dropout所带来的的性质。==注意观察==



## Twisted

Twisted是一款异步开发工具

### reactor 事件管理器

在大量的实践中，似乎我们总是通过类似的方式来使用异步编程：

- 监听事件
- 事件发生执行对应的回调函数
- 回调完成（可能产生新的事件添加进监听队列）
- 回到1，监听事件

因此我们将这样的异步模式称为Reactor模式，Twisted程序就是在等待事件、处理事件的过程中不断循环，

reactor是事件管理器，用于注册、注销事件，运行事件循环，当事件发生时调用回调函数处理。关于reactor有下面几个结论:

- Twisted的reactor只有通过调用reactor.run()来启动。
- reactor循环是在其开始的进程中运行，也就是运行在主进程中。
- 一旦启动，就会一直运行下去。reactor就会在程序的控制下（或者具体在一个启动它的线程的控制下）。
- reactor循环并不会消耗任何CPU的资源。
- 并不需要显式的创建reactor，只需要引入就OK了。

`reactor.listenTCP()`注册了一个监听事件，整个逻辑很简单，和正常的server端一样，创建套接字、绑定、监听。不同的是将套接字的描述符添加到了reactor的读集合。那么假如有了client连接过来的话，reactor会监控到，然后触发事件处理程序。

### factory

 **factory** 在twisted框架中负责连接，通信时建立连接，以及连接中断的处理。如下最简单的客户端的例子：

当调用connectTCP的时候初始化TestFactory，没有实际得开始连接，当执行run()的时候开始连接，连接完成会自动调用connectionMade，没有连接上（比如端口没开放）会调用连接失败函数，丢失连接会自动调用丢失函数。所以说factory主要控制连接，初始化协议（执行会话所需的协议）。

### Protocol

-   **Protocol**负责会话，数据的传输。比如我们可以重载datarecv、lineRec eived等函数，就可以在收到信息的时候处理。如下程序，是简单服务器重载lineReceived：

### Deferred

用于处理回调，当异步处理中的结果返回时，Deferred将会启动并以添加时的顺序触发回调链。

如果您的关键部分是异步的并且需要保护其不被重叠（可能会说“并发”）执行，请使用`DeferredLock`。

## conda配置新环境

1. 创建新环境：`conda create -n myenv python=3.6.1` 
2. 激活环境：`conda activate` 
3. 退出环境：`conda deactivate` 
4. 删除环境：`conda remove -n myenv --all` 
5. 查看当前所有环境：`conda info --envs` / `conda env list` 
6. STD-NET项目，配置tensorflow 1.12环境时，每次增加：
   `export LD_LIBRARY_PATH="/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64"` 

## Screen Linux

参考文章 http://cmd.52ubuntu.com/c/screen.html 

1. 会话列表`screen -ls`

2. 进入已经创建的会话`screen -r myscreen`

3. 创建会话`screen -S myscreen2`

4. 会话分离`screen -d myscreen` 相当于使用快捷键`Ctrl + a + d` 

5. 删除会话：首先进入会话，然后输入exit命令。

6. 在一个会话中创建多个窗口

   ```
   ctrl + a，d #暂离当前会话
   ctrl + a，c #在当前screen会话中创建一个窗口
   ctrl + a，w #窗口列表
   ctrl + a，p #上一个窗口
   ctrl + a，n #下一个窗口
   ctrl + a，0-9 #在第0窗口至第9窗口间切换
   ctrl + d #退出（关闭）当前窗口
   ```

7. 如果使用screen -ls发现有会话是Attached状态，此时不能使用-r直接进入，需要使用命令`screen -D -r 对应的id` 这样才能进入这个会话。



# pygame

### 非常全的中文博客：

[pygame博客主页](https://so.csdn.net/so/search?q=pygame&t=blog&u=qq_41556318) （可以直接在博客中进行搜索）

### pygame.Surface

[对Surface讲解的非常通透的文章](https://blog.csdn.net/zengxiantao1994/article/details/60334247) 

pygame中用于表示图像的对象。

创建Surface的两种方法：

1. 对于Pygame而已，加载图片就是pygame.image.load，给它一个文件名然后就还给你一个surface对象。
2. 另外一种方法是指定尺寸创建一个空的surface，下面的语句创建一个256×256像素的surface：`bland_surface = pygame.Surface((256, 256))` 如果不指定尺寸，那么就创建一个和屏幕一样大小的。

```python
# 有两种初始化方法
Surface((width, height), flags=0, depth=0, masks=None) -> Surface

Surface((width, height), flags=0, Surface) -> Surface
```

你还有两个参数可选，第一个是flags：

HWSURFACE – 类似于前面讲的，更快！不过最好不设定，Pygmae可以自己优化。
SRCALPHA – 有==Alpha通道==的surface，如果你需要透明，就要这个选项。这个选项的使用需要第二个参数为32~

```python
surf = pygame.Surface(fsize, pygame.locals.SRCALPHA, 32)
```



# matlab使用

1. 不启用图形界面：`matlab -nodisplay`
2. 查看现在使用的GPU：`gpuDevice`
3. 更换使用的GPU：`g=gpuDevice(2)  reset(g)`
4. 执行m文件：直接输入文件名，不带m后缀
5. 直接使用命令行一步到位：matlab -nodisplay -r lily_for







---

------







# 遇到的bug

### 模型下载错误导致

`_pickle.UnpicklingError: invalid load key, '<'.` 

一般是由于模型下载的时候出错，可以查看模型大小，如果是几kb，说明下载成网页了，重新下载即可。





# 遇到的系统配置问题

每次遇到系统配置的问题总是很让人头疼，所以想着将遇到的记录一下，以后方便快速解决。

## 非root用户升级gcc

由于用的是学校的服务器，没有root权限，因此需要采用这种方式升级gcc

整体来说需要以下流程：

1. 下载gcc安装包 可能需要加入不检查网络证书的命令

   ```
   wget --no-check-certificate https://ftp.gnu.org/gnu/gcc/gcc-7.5.0/gcc-7.5.0.tar.gz
   ```

2. 解压gcc安装包后 还需要下载四个依赖，不过可以通过命令实现自动下载这些依赖。进入源码目录输入：

   ```
   ./contrib/download_prerequisites
   ```

3. 逐个解压这些依赖安装包，并加入软链接。

   ```
   tar -jxvf mpfr-3.1.4.tar.bz2       
   ln -sf mpfr-3.1.4  mpfr     
   tar -jxvf gmp-6.1.0.tar.bz2
   ln –sf gmp-6.1.0 gmp
   tar -zxvf mpc-1.0.3.tar.gz
   ln –sf mpc-1.0.3  mpc
   tar -jxvf isl-0.16.1.tar.bz2
   ln -sf isl-0.16.1 isl
   ```

4. 编译gcc （注意：这里需要将gcc编译到自己的目录里，这样就不会产生权限的问题啦）

   ```
   cd gcc-4.8.5
   mkdir objdir  
   cd objdir
   ../configure --disable-checking --enable-languages=c,c++ --disable-multilib --prefix=/home/lily/myinstall/gcc-7.5 --enable-threads=posix
   make -j64 # 使用多线程可以加快编译速度
   make install  #安装 
   ```

5. 配置环境变量，简单加入两行就OK了。

   ```
   vim ~/.bashrc
   export PATH=/home/lily/myinstall/gcc-7.5/bin:/home/lily/myinstall/gcc-7.5/lib64:$PATH
   export LD_LIBRARY_PATH=/home/lily/myinstall/gcc-7.5/lib/:$LD_LIBRARY_PATH
   source ~/.bashrc  //更新该文件
   ```

6. 查看gcc版本

   ```
   gcc --version
   ```

如果出现bug：LIBRARY_PATH shouldn't contain the current directory
查看是不是LIBRARY_PATH环境变量中出现了两个冒号连在一起，删除一个即可。
[LIBRARY_PATH shouldn't 解决办法](https://github.com/Linuxbrew/legacy-linuxbrew/issues/807)

参考文章：

[gcc的更新](https://blog.csdn.net/weixin_41010198/article/details/106780572) 

[Linux下非root用户解决限制gcc、g++版本升级问题_](https://blog.csdn.net/weixin_43803635/article/details/103406158) 

[非root权限升级Linux gcc版本_](https://blog.csdn.net/OliverkingLi/article/details/89645710) 

## 动态文件libstdc++.so.6

**冷静思考**

/lib64/libstdc++.so.6 中的GLIBCXX 版本比较低，导致一些第三方库**默认引用**的时候会找不到自己需要的版本。    那么我们就需要把默认引用修改为anaconda中版本足够高的位置（/home/lily/anaconda3/lib/libstdc++.so.6）

```
vim /home/lily/.bashrc
# 增加这一句
export LD_LIBRARY_PATH=/data/lily/anaconda3/lib:$LD_LIBRARY_PATH
# 或者查看一下LD_LIBRARY_PATH路径对不对 一般是这样：/home/lily/anaconda3/lib/
vim ~/.bash_profile
```



# Docker

[什么是Docker？看这一篇干货文章就够了！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/187505981)

## 容器技术

与虚拟机通过操作系统实现隔离不同，容器技术**只隔离应用程序的运行时环境但容器之间可以共享同一个操作系统**，这里的运行时环境指的是程序运行依赖的各种库以及配置。

## 什么是Docker

容器是一种通用技术，docker只是其中的一种实现。

**程序的表现只和集装箱有关系(容器)，和集装箱放在哪个货船或者哪个港口(操作系统)没有关系**。可以看到docker可以屏蔽环境差异。

## 如何使用Docker

docker中有这样几个概念：

- dockerfile
- image
- container

实际上你可以简单的把image理解为可执行程序，container就是运行起来的进程。

那么写程序需要源代码，那么“写”image就需要dockerfile，dockerfile就是image的源代码，docker就是"编译器"。

因此我们只需要在dockerfile中指定需要哪些程序、依赖什么样的配置，之后把dockerfile交给“编译器”docker进行“编译”，也就是docker build命令，生成的可执行程序就是image，之后就可以运行这个image了，这就是docker run命令，image运行起来后就是docker container。

具体的使用方法就不再这里赘述了，大家可以参考docker的官方文档，那里有详细的讲解。

## Docker pull

我们之前说过，docker中image的概念就类似于“可执行程序”，我们可以从哪里下载到别人写好的应用程序呢？很简单，那就是APP Store，即应用商店。与之类似，既然image也是一种“可执行程序”，那么有没有"Docker Image Store"呢？答案是肯定的，这就是Docker Hub，docker官方的“应用商店”，你可以在这里下载到别人编写好的image，这样你就不用自己编写dockerfile了。

docker registry 可以用来存放各种image，公共的可以供任何人下载image的仓库就是docker Hub。那么该怎么从Docker Hub中下载image呢，就是这里的docker pull命令了。

因此，这个命令的实现也很简单，那就是用户通过docker client发送命令，docker daemon接收到命令后向docker registry发送image下载请求，下载后存放在本地，这样我们就可以使用image了。

# PSCC-Net

1. 什么是encoder-decoder?

   - encoder-decoder其实就是模拟人类认知的一个过程，人类认识事物通过形成概念、直觉、判断，encoder-decoder就是在模拟这一信息处理的过程。
     encoder理解记忆信息，并提炼信息形成一个低秩的向量，在这一过程中，可以仅依赖输入的信息，也可以加入一些其他规则或者attention机制等，就如同人在认识一个新事物时，也会利用之前的经验来试图理解。
     decoder回忆并运用这些信息，再将低秩的编码信息抽取出来，混合其他信息，解码成需要的形式。

   - encoder-decoder可以参考这个模型：
     <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211009194028748.png" alt="image-20211009194028748" style="zoom:80%;" />

     encoder部分的RNN是没有输出的，所以说encoder的作用就是接受了一个词向量，产生了一个隐藏层向量。
     decoder解码器一个重要的作用就是输出结果，利用encoder传来的隐层向量（将作为decoder的初始状态）和decoder的输入来继续编码。
     decoder和encoder相比多了一个用于输出词概率的全连接层，所以encoder-decoder模型可以看做是两个编码器进行联合训练得到的语言模型。

   - [具体实现](https://zhuanlan.zhihu.com/p/27608348) 

2. 轻量级主干网络 light-weight backbone
   [知乎文章](https://zhuanlan.zhihu.com/p/414512764) 
   轻量级网络的核心是在尽量保持精度的前提下，从体积和速度两方面对网络进行轻量化改造
   主要有这些网络：SqueezeNet SqueezeNext MobileNet ESPNet EfficientNet WeightNet MobileNext

   - 主要了解一下SqueezeNet：
     是早期但是经典的轻量级网络，SqueezeNet使用Fire模块进行参数压缩，而SqueezeNext则在此基础上加入分离卷积进行改进。
     使用Fire模块进行参数压缩。
     ==优点==更高效的分布式训练，小模型参数小，网络通信量减少，便于模型更新。
     ==模型压缩的几个方面==基本是在四个方面：

     1. 模型压缩：对预训练pre-trained的模型进行压缩，利用SVD，剪枝，量化等操作缩小模型。
     2. CNN微观结构：对单个卷积层进行优化设计，采用1X1的小卷积核。
     3. CNN宏观结构：网络架构设计，网络深度减少，或者ResNet那样使用短路连接。
     4. 设计空间：不同超参数，网络结构，优化器组合优化。

     ==SqueezeNet的设计原理==：

     1. 大量使用1*1卷积核替换3 *3卷积核，因此参数可以降低9倍；

     2. 减少3*3卷积核的输入通道数；

     3. 延迟下采样，前面的layers可以有更大的特征图，有利于提高模型准确度。

     4. > 下采样/降采样：缩小图像，比如池化就是降采样的一种方法
        >
        > 下采样的目的：生成图像对应的缩略图，减低特征的维度并保留有效信息，一定程度上避免了过拟合。
        >
        > 上采样/图像插值：放大原图像，从而可以显示在更高分辨率的显示设备上。
        >
        > 插值的方法：使用均值，中值，最邻近，在像素周围计算丢失的像素；反池化：池化的逆过程，其他位置补0

     5. Fire模块中所有卷积层的激活函数采用ReLU；Fire9层之后采用了dropout；没有全连接层，采用了全局的avgpool层，即pool size与输入的feature map大小一致；采用比较有效的稀疏矩阵存储方式，进而降低模型大小。

3. LSTM [参考文章](https://zhuanlan.zhihu.com/p/32085405) 

   1. 循环神经网络（Recurrent Neural Network，RNN）是一种用于处理序列数据的神经网络。某个单词的意思会因为上文提到的内容不同而有不同的含义，RNN就能够很好地解决这类问题。

   2. <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211010215556710.png" alt="image-20211010215556710" style="zoom: 50%;" />

   3. ==LSTM==长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。
      相比于RNN只有一个传递状态$h^t$, LSTM有两个传递状态$h^t$ 和 $c^t$ (hidden state  &  cell state)，$c^t$通常改变很慢，输出的$c^t$是上一个传过来的$c^{t-1}$加上一些数值，而$h^t$在不同的节点之间往往会有很大区别。![image-20211010220903388](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211010220903388.png)

      <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211010221942943.png" alt="image-20211010221942943" style="zoom: 67%;" />

4. J-LSTM & H-LSTM
   ==重采样==分为上采样和下采样，上采样是通过插值等方法把时间线拉长，下采样是通过压缩数据的方法把时间线缩短。

   1. J-LSTM：一般而言，为了边缘的平滑过度，不被人眼识别出怪异，一般在图像篡改后进行边缘的平滑。
      因此，放大边缘，一般有锯齿的是真实图像，而很明显的没有锯齿痕迹的往往是篡改图像。欲盖弥彰。





# MMSegmentation

标准统一的语义分割框架





