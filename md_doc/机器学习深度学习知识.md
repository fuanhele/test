# 机器学习深度学习知识

> 这里记录非代码的知识



# 数据预处理：

将各个维度特征归一化到同一取值区间，并且消除不同特征之间的相关性，才能获得理想的效果。

## 数据归一化对梯度的影响：

![image-20211026141454068](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211026141454068.png)

### 缩放归一化：

通过缩放将每一个特征的取值范围归一化到[0,1]或[-1,1]之间。

### 标准归一化：

将每一个维度的特征的原分布缩放为标准差为1，均值为0。

## 白化（Whitening）/ 球化

白化是一种重要的预处理方式，用来**降低输入数据特征之间的冗余性**，输入数据经过白化处理后，特征之间相关性降低，并且所有特征具有相同的方差。

白化具有2个目的：**1. 使数据的不同维度去相关；2. 数据每个维度的方差为1。** 

为什么使用白化？  在训练图像时，图像相邻像素之间有很强的相关性，这些是冗余的，白化的目的就是降低输入的冗余性。

### PAC白化

### ZCA白化

在PAC白化的基础上做旋转操作，使得白化后的操作更加接近原始数据。

## 主成分分析（Principal Component Analysis ：PCA）

通过==正交变换==将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量叫主成分。

**PCA的思想是将n维特征映射到k维上（k<n），这k维是全新的正交特征。**这k维特征称为主成分，是重新构造出来的k维特征，而不是简单地从n维特征中去除其余n-k维特征。------可以类比为线性代数求矩阵秩的过程。

PCA过程：

1. 特征中心化：每一维数据都减去该维的均值，每一维代表一个特征。
2. 求特征协方差矩阵：
3. 计算协方差矩阵的特征值和特征向量，并归一化为单位向量。
4. 将特征值排序，选择其中最大的k个，将对应的特征向量组成特征向量矩阵。
5. 将样本点投影到特征向量上。这样原始的n维特征就变成了k维。

### one-hot独热编码

对于每一个特征,如果它有m个可能值,那么经过独热编码后,**就变成了m个二元特征**.并且,这些特征互斥,每次只有一个激活.因此,数据会变成稀疏的。

这样做的好处主要有：1. 解决了分类器不好处理属性数据的问题；2. 在一定程度上也起到了扩充特征的作用。

对于标签数据可以转化为独热编码形式,这对于**网络的分类输出(softmax,多分类)**而言,是更为实际的表达形式。

## 数据增强 Data Augmentation

深层神经网络一般都需要大量的训练数据才能获得比较理想的结果。在**数据量有限的情况**下，可以**通过数据增强来增加训练样本的多样性**， 提高模型鲁棒性，避免过拟合。

- 翻转flip

- 旋转rotation

- 平移shift

- 缩放resize/尺度变换Random Scale

- 随机裁剪或补零Random Crop or Pad

- 色彩抖动Color jittering:HSV颜色空间随机改变图像原有的饱和度和明度（即，改变 S 和 V 通道的值）或对色调(Hue)进行小范围微调。

- 对比度变换contrast:在图像的HSV颜色空间，改变饱和度S和V亮度分量，保持色调H不变. 对每个像素的S和V分量进行指数运算(指数因子在0.25到4之间), 增加光照变化;

- PCA抖动PCA Jittering：首先按照RGB三个颜色通道计算均值和标准差，再在整个训练集上计算协方差矩阵，进行特征分解，得到特征向量和特征值，用来做PCA Jittering；

- 加噪声（Noise）

- 特殊的数据增强方法：

- - Fancy PCA（Alexnet）& 监督式数据扩充（海康）
  - 使用生成对抗网络（GAN） 生成模拟图像



## 正则化

[参考文章](https://www.cnblogs.com/zingp/p/10375691.html) 

L1-norm  L2-norm

正则化 和 正则表达式 没有任何联系！！！

正则化：用各种方法去规范模型参数的方法(对损失函数的参数做出一些限制)。DropOut也是一种正则化。使用L1正则化的模型叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。

L1正则化是指权值向量ww中各个元素的绝对值之和，通常表示为$\parallel W \parallel_1$ , L1正则化可以使参数稀疏化，即得到的参数是一个稀疏矩阵，可以用于特征选择。（ 稀疏矩阵：说明矩阵中的很多参数都是0，表示有很多参数都是无足挂齿的，只有那些非零的参数才对模型有贡献，我们主要就关注这些非零的参数，这样可以留下重要的特征，提高模型的泛化能力，降低过拟合的可能）

L2正则化是指权值向量ww中各个元素的平方和然后再求平方根（可以看到Ridge回归的L2正则化项有平方符号），通常表示为$\parallel W \parallel_2$。L2正则化可以防止模型过拟合。

花书中对正则化的定义：凡是可以减少泛化误差 而不是减少训练误差的方法，都可以称作正则化方法。（简单来说：凡是能减少过拟合的方法都是正则化方法）

L2范数：欧式距离，图像是一个圆

L1范数：曼哈顿距离，图像是一个旋转45°的正方形

注意：在两组计算中，即使得到的损失函数的值一样，但是w和b的取值很可能不相同，主要取决于w和b的初始值设置(其实最主要的还是w，因为w的值决定了这个模型的形状，而参数b仅决定偏移量)。所以为了不让这两个参数太大，我们就需要 把这两个参数的取值范围放到一个框框里。

如何表示将参数w的距离放到一个框框里呢：
$$
\parallel W \parallel_1
-C \leq 0
$$
这个$\parallel W \parallel_1$表示参数w到原点的L1距离（曼哈顿距离）。

正则化确实会带来一些偏差但是这些偏差没有那么大。







## SVM支持向量机Support Vector Machine

又称Large Margin Classifer大间隔分类器

基本逻辑就是 既要找到一条分割线能使样本点分隔开，又要找到两个边界分界面的距离最远。

对于一些线性可分的数据集来说，可以找到这样一个合适的分割线，但是对于线性不可分的数据集来说，我们只有将一些混乱的样本实为错误的样本，才能找到合适的分割线，保证较大的准确性，我们称这样的为Soft-Margin SVM。

不过说到底，SVM还是一个线性分类器，对于一些非线性的数据集，无法用这个方法区分， 这就引入了Kernel，我们可以引用更高维度来将低维中线性不可分变成高维中线性可分。

Hyperplane：超平面  Kernel：核函数

## checkpoint

什么是checkpoint？这是一种为长时间运行进程准备的容错技术。

在系统故障的时候 拍摄系统快照的方法，一旦出问题不会让进度全部丢失，可以在出问题的地方作为重新运行的起点。

训练深度学习的模型时，checkpoint是模型的权重，可以用来做预测，或作为持续训练的基础。

## BN层

BN层：

BN层期望我们的结果服从高斯分布，所以对神经元的输出进行一下修正，一般放在卷积层后，池化层前。

激活函数一般在[0,1]范围内表现的比较好，所以需要在激活函数之前，将数据保持在[0,1]之间，需BN层的作用。

BN层的作用：

1. **加速网络的训练和收敛的速度**
   - 在深度神经网络中，如果每层数据分布都不一样，会导致网络比较难收敛和训练；而如果每层的均值都为0，方差为1的状态下，这样会比较容易收敛。
2. 控制梯度爆炸**防止梯度消失**
3. 防止过拟合
4. 数据在进行Relu之前不会因为数据过大而导致网络性能的不稳定

BN层的缺点：

如果网络层次比较深，加入BN层可能导致模型训练速度很慢。

BN层的参数：

1. num_features:特征的数量

## advprop

[Adversarial Examples Improve Image Recognition](https://blog.csdn.net/saturdaysunset/article/details/108186808)

采用对抗样本去提升图像识别能力，对抗样本是一种在普通样本数据上加一些噪声信号得到的新数据，这样的样本人类看起来没有什么区别，但是在机器上却是致命的，会使原本识别率很好的网络错误率大大提升。

针对这种情况，作者在论文中提出了一种叫做辅助BN的方法，思想很简单，就是在原本网络里batch norm层（主BN）旁边加了一条旁路，也是batch norm层，因为是要用来给对抗样本进行训练，为了和原本的BN做区分，所以叫做辅助BN。

## hyperparameter

超参 hyperparameter：模型的层数以及每层的大小

模型参数：权重

## 验证集上的评估模型

为什么需要评估模型？评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。在训练数据上训练模型，在验证数据上评估模型。一旦找到了最佳参数，就在测试数据上最后测试一次。

[评估模型的几种方法](

## 损失函数部分

### labelsmooth

参考文章： [深度学习trick--labelsmooth - 云+社区 - 腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1684298)

在做分类任务的时候，标签的值是确定的，比如在做四分类问题时，标签的值就是0 1 2 3 

使用onehot编码的话就是[1000, 0100, 0010, 0001]

这时假设网络输出的结果为[0.1, 0.7, 0.15, 0.05] 对应的标签是 0100， 不使用labelsmooth的话就是计算0.7和1的损失函数值；如果使用labelsmooth（假设$\epsilon$=0.1）对应的标签就是 [0.1/3, 0.9,  0.1/3, 0.1/3] 然后计算每个对应位置的损失函数值，这就是一种smooth。

## PyTorch的自动求导

自动求导是pytorch中非常重要的特性，减少了模型构建的时间。

### 简单情况的自动求导

```python
x = Varibale(torch.Tensor([2]), requires_grad=True)
y = x+2
z = y**2 + 3
print(z) # 19

z.backward() #对当前函数计算梯度
print(x.grad()) # 8
```

### 复杂情况的自动求导

```python
m = Variable(torch.FloatTensor([[2,3]]),requires_grad=True)# 构建一个1*2的矩阵
n = Variable(torch.zeros(1,2))
# 通过m中的值计算新的n中的值
n[0,0] = m[0,0] ** 2
n[0,1] = n[0,1] ** 3
# 计算之后的n=4,27
```

在pytorch中，如果要调用自动求导，需要往`backward()`中传入一个参数，这个参数的形状和n一样大。

```python
n.backward(torch.ones_like(n)) #将(w0,w1)取成(1,1)
print(m.grad) # 4, 27
```

多次求导需要在第一的backward中增加参数`retain_graph=True`,下一次求导结果会和第一次求导结果相加输出。

## KL散度 KL divergence

用来衡量两个分布的差异性，差异越大KL值越大，差异越小值越接近0.

## 反卷积 Transpose Revolution

上采样有3种常见的方法：双线性插值(bilinear)，反卷积(Transposed Convolution)，反池化(Unpooling)，我们这里只讨论反卷积。这里指的反卷积，也叫转置卷积，它并不是正向卷积的完全逆过程，用一句话来解释：

> 反卷积是一种特殊的正向卷积，先按照一定的比例通过补 0来扩大输入图像的尺寸，接着旋转卷积核，再进行正向卷积。

![image-20211015122343396](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211015122343396.png)

如上图所示，先将输入的3*3的特征图，设置padding=1，右侧和下侧填充两行0，然后利用3 *3的卷积核，进行卷积形成6 *6的特征图。

## Variable

能够计算图的tensor，Variable是对tensor的封装，操作和tensor是一样的。
但是每个Variable都有三个属性，

1. Variable中的tensor本身`.data`
2. 对应tensor的梯度`.grad`
3. 以及这个Variable是通过什么方式得到的`.grad_fn`

```python
# 导入Variable
from torch.autograd import Variable
x_tensor = torch.randn(10,5)
y_tensor = torch.randn(10,5)
# 将tensor变成Variable
x = Variable(x_tensor, requires_grad=True) #默认不需要求梯度，所以这里需要设置这个参数
y = Variable(y_tensor, requires_grad=True)
# 对这两个tensor求和
z = torch.sum(x + y)
print(z.data) # -2.1379[torch.FloatTensor of size 1]
print(z.grad_fn) #<SumBackward0	object	at 0x10da636a0>
# 求x和y的梯度
z.backward()
print(x.grad)
print(y.grad)
```

### dice系数

用来评价两个事物相似度，越接近于1说明效果越好。

![image-20211020171427506](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211020171427506.png)

## SRM

风格的重新校准模块，主要由两个组件组成：Style Polling和Style Integration。

Polling用来提取风格，Integration用来根据风格生成权重。

# 神经网络一般步骤

1. 前向传播
   - 计算预测值
   - 计算损失值
2. 反向传播
   - 梯度归零
   - 计算梯度
   - 梯度下降
3. 计算正确率
   1. 







# 篡改检测：

英文表达：manipulation  tamper  forgery

图像篡改粗略分为两类：

1. Manipulation：中值滤波处理Median Filtering、高斯模糊Gaussian Blurring、添加高斯白噪声Additive White Gaussian Noise、重采样Resampling、JPEG压缩JPEG Compression。
2. Temper：删除Removal、添加Adding、复制Copy、截取Splicing

篡改检测实际上就是要将图像中改动的区域找出来。

近几年学术上趋于研究：splicing、copy-move、removal这三类。

1. splicing：一张图扣下来粘到另一张图上
2. copy-move：将图片上的一部分复制并粘贴在其他位置
3. removal：将图上的一部分内容擦除掉

篡改检测一般有以下三个研究方向：

1. 预处理pre-processing
2. 特征提取CNN
3. 后处理post-processing、

篡改检测方向四个出名的公开数据集：

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211008194120891.png" alt="image-20211008194120891" style="zoom:50%;" />

[引用文章](https://zhuanlan.zhihu.com/p/85030394) 







# 模型评价指标

[知乎文章](https://zhuanlan.zhihu.com/p/92495276) 

## AUC指标：

AUC是一个模型评价指标，用于二分类模型的评价。AUC是“Area under Curve（曲线下的面积）”的英文缩写，而这条“Curve（曲线）”就是ROC曲线。数值越高，这个分类器越优秀。

ROC：受试者工作特征曲线

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211028210953581.png" alt="image-20211028210953581" style="zoom:80%;" />

什么要用AUC作为二分类模型的评价指标呢？为什么不直接通过计算准确率来对模型进行评价呢？
答案是这样的：机器学习中的很多模型对于分类问题的预测结果大多是概率，即属于某个类别的概率，如果计算准确率的话，就要把概率转化为类别，这就需要设定一个阈值，概率大于某个阈值的属于一类，概率小于某个阈值的属于另一类，==而阈值的设定直接影响了准确率的计算==。使用AUC可以解决这个问题，接下来详细介绍AUC的计算。

例如，数据集一共有5个样本，真实类别为（1，0，0，1，0）；二分类机器学习模型，得到的预测结果为（0.5，0.6，0.4，0.7，0.3）。将预测结果转化为类别——预测结果降序排列，以**每个预测值（概率值）作为阈值**，即可得到类别。计算每个阈值下的“True Positive Rate”、“False Positive Rate”。以“True Positive Rate”作为纵轴，以“False Positive Rate”作为横轴，画出ROC曲线，ROC曲线下的面积，即为AUC的值。

True Positive Rate=TP/(TP+FN)，代表将真实正样本划分为正样本的概率
False Positive Rate=FP/(FP+TN)，代表将真实负样本划分为正样本的概率

```python
from sklearn.metrics import roc_curve,auc
#roc_cure()是绘制roc曲线，返回值为fpr,tpr,thredholds
fpr,tpr,thredholds = roc_curve(y,prob)
#auc计算roc曲线下的面积
auc_=auc(fpr,tpr)
plt.plot(fpr,tpr)
plt.legend(['auc:%0.2f'%(auc_)])
```

## F1 Score Precision Recall

![image-20211028170232625](C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211028170232625.png)

Precision衡量是否有误判：A+C是模型判断‘患癌症’的病人，A是其中真正‘患癌症’的病人，那Precision就是，模型判定‘患病’的准确度。

Recall用来衡量是否有遗漏：A+B是所有真实患癌症的病人，A是模型筛查出患病的病人。

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211028170600145.png" alt="image-20211028170600145" style="zoom:80%;" />

Precision：被我们的算法选为positive的数据中，有多少真的是positive的？

Recall: 实际应该为Positive的数据中，多少被我们选为了Positive？

Accuracy: 所有数据中，我们正确分类了多少？

F1 Score是precision和recall整合在一起的判定标准。在最初的例子中，如果模型只输出‘健康’，而无法成功辨别任何一例‘癌症’病人，那么F1 Score将会被直接归零。

### IOU

IOU=交集 / 并集

中文名：交并比，通常用于目标检测预测框之间准确度的一个度量。通常阈值设置0.5

### TP TN FP FN

**T-Ture;F-False 表示预测结果的正确性，T表示预测正确，F表示预测错误； P-positive;N-negative 表示预测的正负性，P表示预测为正样本，N表示预测为负样本；**

- TP——True Positive真正例，表示样本为正，预测值为正——预测正确T
- FP——False Positive假正例，表示样本为负，预测值为正——预测错误F
- FN——False Negative假负例，表示样本为正，预测值为负——预测错误F
- TN——True Negative真负例，表示样本为负，预测值为负——预测正确T

### Accuracy

预测正确的样本数/总样本数

### AP

平均精准率 ：每一个类别的样本精准率 / 样本总和。





### 自监督学习

[参考一篇讲述很好的文章](https://note.youdao.com/ynoteshare/index.html?id=56870b06d62007e81117cd1f7c38ade1&type=note&_time=1648642981650) 

自监督学习主要是利用辅助任务（pretext）从大规模的无标签数据中挖掘自身的监督信息，通过这种构造的监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征。

自监督学习的核心，在于如何自动为数据产生标签。例如输入一张图片，把图片随机旋转一个角度，然后把旋转后的图片作为输入，随机旋转的角度作为标签。再例如，把输入的图片均匀分割成3*3的格子，每个格子里面的内容作为一个patch，随机打乱patch的排列顺序，然后用打乱顺序的patch作为输入，正确的排列顺序作为label。类似这种自动产生的标注，完全无需人工参与。（设计带标签的辅助任务）

在自监督学习中，用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task)。

### JPEG的量化 DCT

关键词： JPEG图片压缩， RGB->YUV ，离散余弦变换

[写的非常非常详细通透的一篇文章](https://blog.csdn.net/newchenxf/article/details/51719597)

[JPEG图像压缩算法流程详解](https://www.elecfans.com/dianzichangshi/20171201590267_a.html)

YUV：是一种图像数据表示方法，Y：颜色的亮度 灰度值 U：色调 V：饱和度

YUV的某些格式，和RGB比起来，其数据量要少很多

YUV与RGB可以互相转换。

DCT变换公式：

![image-20220331090913370](C:\Users\lly\AppData\Roaming\Typora\typora-user-images\image-20220331090913370.png)

图片经过DCT处理后，数据就不同了，左上方都是大数值（低频数据），右下方都是小数值（高频数据）。



### 课程学习

[参考知乎文章](https://zhuanlan.zhihu.com/p/362351969)

**课程学习 (Curriculum learning, CL)** 是近几年逐渐热门的一个前沿方向。Bengio [1] 首先提出了课程学习（Curriculum learning，CL）的概念，它是一种训练策略，**模仿人类的学习过程，主张让模型先从容易的样本开始学习，并逐渐进阶到复杂的样本和知识**。CL策略在计算机视觉和自然语言处理等多种场景下，在提高各种模型的泛化能力和收敛率方面表现出了强大的能力。

每个任务每个数据的学习优先程度  由难度测量器定义；
什么时候把有难度的任务或者数据输入训练或者输入多少呢 由训练调度器定义。

课程学习可以分为 预训练CL（人类定义）和 自动CL（由数据自己来决定）。
自动CL 有： Self-paced learning，Transfer Teacher，RL Teacher



### Benchmark和baseline

[参考文章讲解的很清楚](https://blog.csdn.net/qq_37791134/article/details/84962058)

通俗的讲，一个算法之所以被称为benchmark，是因为它的**性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏**。

通俗的讲，一个算法被称为baseline，基本上表示**比这个算法性能还差的基本上不能接受的**. 





### 贝叶斯分类器

提问：文本分类器：一个句子中的单词 为什么可以概率独立？
为什么会有概率为0的情况，是因为单词没有在训练集中出现吗？已解决

推荐系统里面的应用：贝叶斯中的协同过滤



### 图片处理前要除以255原因

imshow是用来显示图片的，如

I = imread('moon.tif');
figure,imshow(I);
而有时为了数据处理，要把读取的图片信息转化为更高的精度，
I = double(imread('moon.tif'));
为了保证精度，经过了运算的图像矩阵I其数据类型会从unit8型变成double型。如果直接运行imshow(I)，我们会发现显示的是一个白色的图像。这是因为imshow()显示图像时对double型是认为在0 ~ 1范围内，即大于1时都是显示为白色，而imshow显示uint8型时是0~255范围。而经过运算的范围在0-255之间的double型数据就被不正常得显示为白色图像了。
有两个解决方法：
1> imshow(I/256); -----------将图像矩阵转化到0-1之间
2> imshow(I,[]); -----------自动调整数据的范围以便于显示.
从实验结果看两种方法都解决了问题，但是从显示的图像看，第二种方法显示的图像明暗黑白对比的强烈些！



## GNN GCN 傅里叶

[图卷积网络综述，写的很好但是现在看不明白](https://zhuanlan.zhihu.com/p/163719010) 

[图神经网络(GNN)及其在视觉/医学图像中的应用](https://zhuanlan.zhihu.com/p/427533727) 

[掐死傅里叶 知乎](https://zhuanlan.zhihu.com/p/19763358) 

[用图片的形式说明了 对图像的做傅里叶转换的过程](https://blog.csdn.net/yinfourever/article/details/121997575) 

[将离散傅里叶变换和快速傅里叶变换用数学推导和代码的形式解释的比较清楚](https://www.cnblogs.com/ECJTUACM-873284962/p/6919424.html) 

[pytorch中怎么进行傅里叶卷积](https://zhuanlan.zhihu.com/p/438509608) 



> https://github.com/pkumivision/FFC，这周帮我做件事，理解一下pytorch中的傅里叶变换方法，然后将其中的傅里叶信号特征换成：振幅、相位、实虚部，进行性能比较



### 将灰度图进行傅里叶变换并展示

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

image = cv2.imread('./img/img33.jpg')
image_grey = cv2.imread('./img/img33.jpg', cv2.IMREAD_GRAYSCALE)

f = np.fft.fft2(image_grey)  # 注意此处需要对灰度图进行傅里叶变换，为什么不能对彩图进行呢？
# 经过测试，需要将RGB三个通道分开进行傅里叶变换
fshift = np.fft.fftshift(f)  # f是一个复数数组，这一步就是将零频率分量移动到频谱中心
fft_img = 20 * np.log(np.abs(fshift))  # 需要把复数映射到[0,255]之间

fig, ax = plt.subplots(1, 2)  # row = 1, col = 2

ax[0].imshow(image_grey, cmap='gray')
ax[1].imshow(fft_img, cmap='gray')

ax[0].axis("off"), ax[1].axis("off")

# plt.savefig("result.jpg", dpi = 300, bbox_inches = "tight")
plt.show()
```





